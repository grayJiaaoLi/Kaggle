{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-23T18:48:34.335239Z","iopub.execute_input":"2023-09-23T18:48:34.335631Z","iopub.status.idle":"2023-09-23T18:48:34.586760Z","shell.execute_reply.started":"2023-09-23T18:48:34.335594Z","shell.execute_reply":"2023-09-23T18:48:34.585544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_decision_forests as tfdf\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-23T18:48:34.589004Z","iopub.execute_input":"2023-09-23T18:48:34.589613Z","iopub.status.idle":"2023-09-23T18:48:45.092568Z","shell.execute_reply.started":"2023-09-23T18:48:34.589576Z","shell.execute_reply":"2023-09-23T18:48:45.091006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test import\nprint(\"TensorFlow v\" + tf.__version__)\nprint(\"TensorFlow Decision Forests v\" + tfdf.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T18:48:45.095253Z","iopub.execute_input":"2023-09-23T18:48:45.096001Z","iopub.status.idle":"2023-09-23T18:48:45.102911Z","shell.execute_reply.started":"2023-09-23T18:48:45.095969Z","shell.execute_reply":"2023-09-23T18:48:45.101575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load the Dataset","metadata":{}},{"cell_type":"code","source":"# load dataset into a Pandas DataFrame\ndataset_df = pd.read_csv('/kaggle/input/spaceship-titanic/train.csv')\nprint(\"Full train dataset shape is {}\".format(dataset_df.shape))","metadata":{"execution":{"iopub.status.busy":"2023-09-23T18:48:45.104310Z","iopub.execute_input":"2023-09-23T18:48:45.104612Z","iopub.status.idle":"2023-09-23T18:48:45.164619Z","shell.execute_reply.started":"2023-09-23T18:48:45.104588Z","shell.execute_reply":"2023-09-23T18:48:45.163553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# display the first 5 examples\ndataset_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T18:48:45.167404Z","iopub.execute_input":"2023-09-23T18:48:45.167695Z","iopub.status.idle":"2023-09-23T18:48:45.199865Z","shell.execute_reply.started":"2023-09-23T18:48:45.167673Z","shell.execute_reply":"2023-09-23T18:48:45.198863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Basic Exploration of the Dataset","metadata":{}},{"cell_type":"code","source":"dataset_df.describe()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T18:48:45.200992Z","iopub.execute_input":"2023-09-23T18:48:45.201743Z","iopub.status.idle":"2023-09-23T18:48:45.234559Z","shell.execute_reply.started":"2023-09-23T18:48:45.201691Z","shell.execute_reply":"2023-09-23T18:48:45.233659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_df.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T18:48:45.235951Z","iopub.execute_input":"2023-09-23T18:48:45.236927Z","iopub.status.idle":"2023-09-23T18:48:45.264882Z","shell.execute_reply.started":"2023-09-23T18:48:45.236899Z","shell.execute_reply":"2023-09-23T18:48:45.264033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bar Chart for label column:\n### Transported","metadata":{}},{"cell_type":"code","source":"# Transported ?\nplot_df = dataset_df.Transported.value_counts()\nplot_df.plot(kind = \"bar\")","metadata":{"execution":{"iopub.status.busy":"2023-09-23T18:48:45.267275Z","iopub.execute_input":"2023-09-23T18:48:45.268653Z","iopub.status.idle":"2023-09-23T18:48:45.481873Z","shell.execute_reply.started":"2023-09-23T18:48:45.268601Z","shell.execute_reply":"2023-09-23T18:48:45.481123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Numerical data distribution","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(5, 1, figsize = (10, 10))\nplt.subplots_adjust(top = 2)\n\nsns.histplot(dataset_df['Age'], color = 'blue', bins = 50, ax = ax[0] );\nsns.histplot(dataset_df['FoodCourt'], color = 'blue', bins = 50, ax = ax[1]);\nsns.histplot(dataset_df['ShoppingMall'], color = 'blue', bins = 50, ax = ax[2]);\nsns.histplot(dataset_df['Spa'], color = 'blue', bins = 50, ax = ax[3]);\nsns.histplot(dataset_df['VRDeck'], color = 'blue', bins = 50, ax = ax[4]);\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-23T18:48:45.482953Z","iopub.execute_input":"2023-09-23T18:48:45.484153Z","iopub.status.idle":"2023-09-23T18:48:47.342381Z","shell.execute_reply.started":"2023-09-23T18:48:45.484070Z","shell.execute_reply":"2023-09-23T18:48:47.341447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare the Dataset\ndrop both PassengerId and Name columns as they are not necessary for model training","metadata":{}},{"cell_type":"code","source":"dataset_df = dataset_df.drop(['PassengerId', 'Name'], axis = 1)\ndataset_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T18:48:47.343415Z","iopub.execute_input":"2023-09-23T18:48:47.343976Z","iopub.status.idle":"2023-09-23T18:48:47.362791Z","shell.execute_reply.started":"2023-09-23T18:48:47.343949Z","shell.execute_reply":"2023-09-23T18:48:47.361502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check for the missing values:","metadata":{}},{"cell_type":"code","source":"dataset_df.isnull().sum().sort_values(ascending = False)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T18:48:47.363849Z","iopub.execute_input":"2023-09-23T18:48:47.364632Z","iopub.status.idle":"2023-09-23T18:48:47.384694Z","shell.execute_reply.started":"2023-09-23T18:48:47.364606Z","shell.execute_reply":"2023-09-23T18:48:47.383294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This dataset contains a mix of numeric, categorical and missing features.\n\nTF-DF supports all these feature types natively, and no preprocessing is required.\n\nBut this dataset also has boolen fields with missing values.\nTF-DF doesn't support boolean fields yet.\nSo we need to convert those field into int\nTo account for the missing values in the boolean fields, we will replace them with zero.\n\nIn this notebook, we will replace null value entries with zero for numerical columns as well and only let TF-Df handle the missing values in caregorical columns.\n\nNote: You can choose to let TF-DF handle missing values in numerical columns if need be.","metadata":{}},{"cell_type":"code","source":"dataset_df[['VIP', 'CryoSleep', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']] = dataset_df[['VIP', 'CryoSleep', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].fillna(value = 0)\ndataset_df.isnull().sum().sort_values(ascending = False)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T18:48:47.385952Z","iopub.execute_input":"2023-09-23T18:48:47.386335Z","iopub.status.idle":"2023-09-23T18:48:47.405474Z","shell.execute_reply.started":"2023-09-23T18:48:47.386304Z","shell.execute_reply":"2023-09-23T18:48:47.404417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since, TF-Df cannot handle boolean columns, we will hae to dajust the labels in column 'Transported', 'CryoSleep' and 'VIP' to conver them into the integer format that TF-DF expects.\n\n","metadata":{}},{"cell_type":"code","source":"label = \"Transported\"\ndataset_df[label] = dataset_df[label].astype(int)\n\ndataset_df['VIP'] = dataset_df['VIP'].astype(int)\ndataset_df['CryoSleep'] = dataset_df['CryoSleep'].astype(int)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-23T18:48:47.406992Z","iopub.execute_input":"2023-09-23T18:48:47.407392Z","iopub.status.idle":"2023-09-23T18:48:47.418859Z","shell.execute_reply.started":"2023-09-23T18:48:47.407361Z","shell.execute_reply":"2023-09-23T18:48:47.417374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The value of column 'Cabin' is string with the fomat 'Deck/Cabin_num/Side'.\nHere we will split the Cabin column and create 3 new columns 'Deck', 'Cabin_num' and 'Side', since it will be easier to train the model on those individual data.\n\nRun the following command to split the column Cabin into columns Deck,Cabin_num and Side","metadata":{}},{"cell_type":"code","source":"dataset_df[[\"Deck\", \"Cabin_num\", \"Side\"]] = dataset_df[\"Cabin\"].str.split(\"/\", expand = True)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T18:48:47.423371Z","iopub.execute_input":"2023-09-23T18:48:47.423691Z","iopub.status.idle":"2023-09-23T18:48:47.445504Z","shell.execute_reply.started":"2023-09-23T18:48:47.423667Z","shell.execute_reply":"2023-09-23T18:48:47.444373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Remove original Cabin column from the dataset since it is not needed anymore","metadata":{}},{"cell_type":"code","source":"try:\n    dataset_df = dataset_df.drop('Cabin', axis = 1)\nexcept KeyError:\n    print(\"Field does not exist\")","metadata":{"execution":{"iopub.status.busy":"2023-09-23T18:48:47.446715Z","iopub.execute_input":"2023-09-23T18:48:47.447032Z","iopub.status.idle":"2023-09-23T18:48:47.462695Z","shell.execute_reply.started":"2023-09-23T18:48:47.447003Z","shell.execute_reply":"2023-09-23T18:48:47.461462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Display first 5 examples from the prepared dataset","metadata":{}},{"cell_type":"code","source":"dataset_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T18:48:47.463889Z","iopub.execute_input":"2023-09-23T18:48:47.464232Z","iopub.status.idle":"2023-09-23T18:48:47.492462Z","shell.execute_reply.started":"2023-09-23T18:48:47.464200Z","shell.execute_reply":"2023-09-23T18:48:47.491262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split the dataset into training and test datasets","metadata":{}},{"cell_type":"code","source":"def split_dataset(dataset, test_ratio = 0.20):\n    test_indices = np.random.rand(len(dataset)) < test_ratio\n    return dataset[~test_indices], dataset[test_indices]\n\ntrain_ds_pd, valid_ds_pd = split_dataset(dataset_df)\nprint(\"{} examples in training, {} examples in testing.\".format(len(train_ds_pd), len(valid_ds_pd)))\n\n\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-23T18:48:47.493265Z","iopub.execute_input":"2023-09-23T18:48:47.493494Z","iopub.status.idle":"2023-09-23T18:48:47.508034Z","shell.execute_reply.started":"2023-09-23T18:48:47.493472Z","shell.execute_reply":"2023-09-23T18:48:47.506364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is no more step required before we can train the model.\nWe need convert the dataset from Pandas format into TensorFlow Datasets format.\n","metadata":{}},{"cell_type":"code","source":"train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label = label)\nvalid_ds = tfdf.keras.pd_dataframe_to_tf_dataset(valid_ds_pd, label = label)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T18:48:47.509847Z","iopub.execute_input":"2023-09-23T18:48:47.510396Z","iopub.status.idle":"2023-09-23T18:48:47.655553Z","shell.execute_reply.started":"2023-09-23T18:48:47.510364Z","shell.execute_reply":"2023-09-23T18:48:47.654475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Select a Model\n\nTo start, we will work with a Random Forest.\nWe can list all the available models in TensorFlow Decision Forests using the following code:\n","metadata":{}},{"cell_type":"code","source":"tfdf.keras.get_all_models()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T18:48:47.656750Z","iopub.execute_input":"2023-09-23T18:48:47.657072Z","iopub.status.idle":"2023-09-23T18:48:47.664663Z","shell.execute_reply.started":"2023-09-23T18:48:47.657044Z","shell.execute_reply":"2023-09-23T18:48:47.663427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Configure the Model\nWe will use the defaults to create the Random Forest Model.\nBy default the model is set to train for a classification task\n","metadata":{}},{"cell_type":"code","source":"rf = tfdf.keras.RandomForestModel()\n# optional, you can use this to include a list of eval merics\nrf.compile(metrics = [\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2023-09-23T18:48:47.666340Z","iopub.execute_input":"2023-09-23T18:48:47.666711Z","iopub.status.idle":"2023-09-23T18:48:47.725244Z","shell.execute_reply.started":"2023-09-23T18:48:47.666680Z","shell.execute_reply":"2023-09-23T18:48:47.723927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train the model\nwe will train the model using a one-liner\nthe waring about Autograoh can be ignored","metadata":{}},{"cell_type":"code","source":"rf.fit(x = train_ds)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T18:48:47.726460Z","iopub.execute_input":"2023-09-23T18:48:47.726724Z","iopub.status.idle":"2023-09-23T18:49:34.786502Z","shell.execute_reply.started":"2023-09-23T18:48:47.726702Z","shell.execute_reply":"2023-09-23T18:49:34.785189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualize the model\none benefit to tree-based models is that we can easily visualize them.\nThe default number of trees used in the Random Forests is 300.\nWe can select a tree to display below.","metadata":{}},{"cell_type":"code","source":"tfdf.model_plotter.plot_model_in_colab(rf, tree_idx = 0, max_depth = 3)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T18:49:34.787837Z","iopub.execute_input":"2023-09-23T18:49:34.788166Z","iopub.status.idle":"2023-09-23T18:49:35.155925Z","shell.execute_reply.started":"2023-09-23T18:49:34.788140Z","shell.execute_reply":"2023-09-23T18:49:35.155035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ","metadata":{}},{"cell_type":"markdown","source":"## Evaluate the Model on the Out of Bag(OOB) data and te validation dataset\n\nBefore training the dataset we have manually seperated 20% of the dataset for validation nameds as valid_ds.\n\nWe can also use Out of Bag(OOB) score to validate our RandomForestModel.\nTo train a Random Forest Model, a set of random samples from training set are choosen by the alogorihm and the rest of the samples are used to finetune the model.\nThe subset of data that is not chosen is known as Out of Bag data.\nOOB score is computed on the OOb data.\n\nThe training logs show the accurary evaluated on the out of bag dataset according to the number of trees in the model.\n\n**Note: Larger values are better fot this hyperparameter**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nlogs = rf.make_inspector().training_logs()\nplt.plot([log.num_trees for log in logs], [log.evaluation.accuracy for log in logs])\nplt.xlabel(\"Number of Trees\")\nplt.ylabel(\"Accuracy (Out-Of-Bag)\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T18:49:35.157511Z","iopub.execute_input":"2023-09-23T18:49:35.157852Z","iopub.status.idle":"2023-09-23T18:49:35.333901Z","shell.execute_reply.started":"2023-09-23T18:49:35.157829Z","shell.execute_reply":"2023-09-23T18:49:35.332253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inspector = rf.make_inspector()\ninspector.evaluation()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T18:56:07.494119Z","iopub.execute_input":"2023-09-23T18:56:07.494447Z","iopub.status.idle":"2023-09-23T18:56:07.503152Z","shell.execute_reply.started":"2023-09-23T18:56:07.494425Z","shell.execute_reply":"2023-09-23T18:56:07.502173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"now, run an evaluation using the validation dataset","metadata":{}},{"cell_type":"code","source":"evaluation = rf.evaluate(x = valid_ds, return_dict = True)\n\nfor name, value in evaluation.items():\n    print(f\"{name}: {value:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-23T18:57:44.872785Z","iopub.execute_input":"2023-09-23T18:57:44.873135Z","iopub.status.idle":"2023-09-23T18:57:45.391831Z","shell.execute_reply.started":"2023-09-23T18:57:44.873109Z","shell.execute_reply":"2023-09-23T18:57:45.390823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Variable importances\nVariable importances generally indicate how much a feature contributes to the model predictions or quality.\nThere are several ways to identify important features using TensorFlow Decision Forests.\nFirstly, list the available Variable Importances for Decision Tress:\n","metadata":{}},{"cell_type":"code","source":"print(f\"Available Variable Importances:\")\n\nfor importance in inspector.variable_importances().keys():\n    print(\"\\t\", importance)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T18:59:57.048471Z","iopub.execute_input":"2023-09-23T18:59:57.048803Z","iopub.status.idle":"2023-09-23T18:59:57.055339Z","shell.execute_reply.started":"2023-09-23T18:59:57.048778Z","shell.execute_reply":"2023-09-23T18:59:57.053844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As an example, display the important features for the Variable Importance NUM_AS_ROOT.\n\nThe larger the importance score for NUM_AS_ROOT, the more impact it has on the out come of the model.\n\nBy default, the list is sorted from the most important to the least.\nFrom the output you can infer that the feature at the top of the list is used as the root node in most number of trees in the random forest than any other feature.\n","metadata":{}},{"cell_type":"code","source":"# each line is : (feature name, (index of the feature), importance score)\ninspector.variable_importances()[\"NUM_AS_ROOT\"]","metadata":{"execution":{"iopub.status.busy":"2023-09-23T19:03:15.091184Z","iopub.execute_input":"2023-09-23T19:03:15.091542Z","iopub.status.idle":"2023-09-23T19:03:15.099714Z","shell.execute_reply.started":"2023-09-23T19:03:15.091517Z","shell.execute_reply":"2023-09-23T19:03:15.098733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"# Load the test dataset\ntest_df = pd.read_csv('/kaggle/input/spaceship-titanic/test.csv')\nsubmission_id = test_df.PassengerId\n\n# Replace NaN values with zero\ntest_df[['VIP', 'CryoSleep']] = test_df[['VIP', 'CryoSleep']].fillna(value=0)\n\n# Creating New Features - Deck, Cabin_num and Side from the column Cabin and remove Cabin\ntest_df[[\"Deck\", \"Cabin_num\", \"Side\"]] = test_df[\"Cabin\"].str.split(\"/\", expand=True)\ntest_df = test_df.drop('Cabin', axis=1)\n\n# Convert boolean to 1's and 0's\ntest_df['VIP'] = test_df['VIP'].astype(int)\ntest_df['CryoSleep'] = test_df['CryoSleep'].astype(int)\n\n# Convert pd dataframe to tf dataset\ntest_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_df)\n\n# Get the predictions for testdata\npredictions = rf.predict(test_ds)\nn_predictions = (predictions > 0.5).astype(bool)\noutput = pd.DataFrame({'PassengerId': submission_id,\n                       'Transported': n_predictions.squeeze()})\n\noutput.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T19:16:11.391618Z","iopub.execute_input":"2023-09-23T19:16:11.391928Z","iopub.status.idle":"2023-09-23T19:16:11.917052Z","shell.execute_reply.started":"2023-09-23T19:16:11.391902Z","shell.execute_reply":"2023-09-23T19:16:11.915876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission_df = pd.read_csv('/kaggle/input/spaceship-titanic/sample_submission.csv')\nsample_submission_df['Transported'] = n_predictions\nsample_submission_df.to_csv('/kaggle/working/submission.csv', index = False)\nsample_submission_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T19:18:22.782229Z","iopub.execute_input":"2023-09-23T19:18:22.782606Z","iopub.status.idle":"2023-09-23T19:18:22.814436Z","shell.execute_reply.started":"2023-09-23T19:18:22.782575Z","shell.execute_reply":"2023-09-23T19:18:22.813199Z"},"trusted":true},"execution_count":null,"outputs":[]}]}